{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from toolbox.machine_learning import get_features_sets, get_data, balance_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get features\n",
    "features = get_features_sets('Aggregated')\n",
    "\n",
    "# Get data\n",
    "scenario = 'present-day'\n",
    "target = 'heat_stress_category'\n",
    "\n",
    "X, y = get_data(scenario, features, target, scaler=True, periods=[['2023-01-01 00:00:00', '2023-01-07 23:00:00']])\n",
    "\n",
    "# Balance data\n",
    "X, y = balance_data(X, y)\n",
    "\n",
    "# Save data\n",
    "pd.concat([X, y], axis=1).to_csv('../results/models/' + scenario + '_ml_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bruno\\.conda\\envs\\ml-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\bruno\\.conda\\envs\\ml-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\bruno\\AppData\\Local\\Temp\\ipykernel_15084\\2811053293.py:39: ResourceWarning: unclosed file <_io.BufferedWriter name='../results/models/present-day_rf_ml_best_model.sav'>\n",
      "  pickle.dump(best_model, open('../results/models/' + scenario + '_rf_ml_best_model.sav', 'wb'))\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "# Refine best performing models on X, y using a pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Import 2 models (RandomForestClassifier, BaggingClassifier)\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "\n",
    "# Define metrics\n",
    "from sklearn.metrics import make_scorer, f1_score, accuracy_score, precision_score, recall_score\n",
    "\n",
    "# Define scoring\n",
    "scoring = {'accuracy': make_scorer(accuracy_score),\n",
    "              'precision': make_scorer(precision_score, average='weighted', zero_division=1),\n",
    "                'recall': make_scorer(recall_score, average='weighted'),\n",
    "                    'f1_score': make_scorer(f1_score, average='weighted')}\n",
    "\n",
    "# Define a pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('clf', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# Define hyperparameters\n",
    "hyperparameters = {\n",
    "    'clf__n_estimators': [100, 200, 300],\n",
    "    'clf__max_depth': [None, 5, 10, 20],\n",
    "    'clf__min_samples_split': [2, 4, 6],\n",
    "    'clf__min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Define grid search\n",
    "clf = GridSearchCV(pipeline, hyperparameters, scoring=scoring, refit='f1_score', cv=5, verbose=0, n_jobs=-1)\n",
    "\n",
    "# Fit and tune model\n",
    "clf.fit(X, y)\n",
    "\n",
    "# Save the best model\n",
    "best_model = clf.best_estimator_\n",
    "pickle.dump(best_model, open('../results/models/' + scenario + '_rf_ml_best_model.sav', 'wb'))\n",
    "\n",
    "# Save the results of the grid search\n",
    "pd.DataFrame(clf.cv_results_).to_csv('../results/models/' + scenario + '_rf_ml_grid_search_results.csv', index=False)\n",
    "\n",
    "# Save the best parameters\n",
    "pd.DataFrame(clf.best_params_, index=[0]).to_csv('../results/models/' + scenario + '_rf_ml_best_params.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\AppData\\Local\\Temp\\ipykernel_15084\\2340032920.py:29: ResourceWarning: unclosed file <_io.BufferedWriter name='../results/models/present-day_bc_ml_best_model.sav'>\n",
      "  pickle.dump(best_model, open('../results/models/' + scenario + '_bc_ml_best_model.sav', 'wb'))\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "# Define a pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('clf', BaggingClassifier())\n",
    "])\n",
    "\n",
    "# Define scoring\n",
    "scoring = {'accuracy': make_scorer(accuracy_score),\n",
    "              'precision': make_scorer(precision_score, average='weighted', zero_division=1),\n",
    "                'recall': make_scorer(recall_score, average='weighted'),\n",
    "                    'f1_score': make_scorer(f1_score, average='weighted')}\n",
    "\n",
    "# Define hyperparameters\n",
    "hyperparameters = {\n",
    "    'clf__n_estimators': [100, 200, 300],\n",
    "    'clf__max_samples': [0.5, 0.75, 1.0],\n",
    "    'clf__max_features': [0.5, 0.75, 1.0],\n",
    "    'clf__bootstrap': [True, False],\n",
    "    'clf__bootstrap_features': [True, False]\n",
    "}\n",
    "\n",
    "# Define grid search\n",
    "clf = GridSearchCV(pipeline, hyperparameters, scoring=scoring, refit='f1_score', cv=5, verbose=0, n_jobs=-1)\n",
    "\n",
    "# Fit and tune model\n",
    "clf.fit(X, y)\n",
    "\n",
    "# Save the best model\n",
    "best_model = clf.best_estimator_\n",
    "pickle.dump(best_model, open('../results/models/' + scenario + '_bc_ml_best_model.sav', 'wb'))\n",
    "\n",
    "# Save the results of the grid search\n",
    "pd.DataFrame(clf.cv_results_).to_csv('../results/models/' + scenario + '_bc_ml_grid_search_results.csv', index=False)\n",
    "\n",
    "# Save the best parameters\n",
    "pd.DataFrame(clf.best_params_, index=[0]).to_csv('../results/models/' + scenario + '_bc_ml_best_params.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
